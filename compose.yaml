services:
  # Kafka broker using KRaft mode
  kafka:
    image: apache/kafka:3.8.0  # Pin specific version instead of latest
    container_name: kafka-broker
    ports:
      - "9092:9092"
    environment:
      # Configure listeners for both docker and host communication
      KAFKA_LISTENERS: CONTROLLER://kafka:9091,HOST://0.0.0.0:9092,DOCKER://0.0.0.0:9093
      KAFKA_ADVERTISED_LISTENERS: HOST://localhost:9092,DOCKER://${KAFKA_BOOTSTRAP_SERVER}
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,DOCKER:PLAINTEXT,HOST:PLAINTEXT

      # Settings required for KRaft mode
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka:9091

      # Listener to use for broker-to-broker communication
      KAFKA_INTER_BROKER_LISTENER_NAME: DOCKER

      # Required for a single node cluster
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1

      # Storage configuration
      KAFKA_LOG_DIRS: /tmp/kraft-combined-logs
      CLUSTER_ID: MkU3OEVBNTcwNTJENDM2Qk

    volumes:
      - kafka-data:/var/lib/kafka/data # Persist Kafka data
    networks:
      - common-network
    healthcheck:
      test: [ "CMD-SHELL", "/opt/kafka/bin/kafka-topics.sh --bootstrap-server localhost:9092 --list || exit 1" ]
      interval: 10s
      timeout: 10s
      retries: 15
      start_period: 30s

  # Kafka UI for managing and monitoring Kafka
  kafka-ui:
    image: kafbat/kafka-ui:main
    container_name: kafka-ui
    ports:
      - 8080:8080
    environment:
      DYNAMIC_CONFIG_ENABLED: "true"
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:9093
    depends_on:
      kafka:
        condition: service_healthy  # Wait for broker to be healthy
    networks:
      - common-network
    healthcheck:
      test: [ "CMD-SHELL", "curl -f http://localhost:8080/ || exit 1" ]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 30s

  # PostgreSQL database for storing data
  postgres:
    image: postgres
    container_name: postgres-db
    restart: always
    # set shared memory limit when using docker compose
    shm_size: 128mb
    # or set shared memory limit when deploy via swarm stack
    ports:
      - "5432:5432"
    environment:
      POSTGRES_DB: ${POSTGRES_DB}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_HOST_AUTH_METHOD: trust # Allow connections without password for local development
      POSTGRES_PORT: 5432  # Specify the port for PostgreSQL
      TZ: Europe/Rome
    volumes:
      - type: tmpfs
        target: /dev/shm
        tmpfs:
          size: 134217728 # 128*2^20 bytes = 128Mb

      - postgres_data:/var/lib/postgresql/data
      - ./postgres/init.sql:/docker-entrypoint-initdb.d/init.sql # Initialize database with SQL script and postgres will run it
      - ./postgres/init-cdc.sh:/docker-entrypoint-initdb.d/init-cdc.sh # CDC configuration script
      - ./postgres/seed.sql:/docker-entrypoint-initdb.d/seed.sql # Seed data
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "postgres"]
      interval: 5s
      timeout: 5s
      retries: 5
    networks:
      - common-network

  # Adminer for database management
  adminer:
    image: adminer
    container_name: adminer
    restart: always
    ports:
      - 8050:8080
    depends_on:
      postgres:
        condition: service_healthy  # Wait for PostgreSQL to be healthy
    networks:
      - common-network

  # Data API service for collecting market data
  market-data-api:
    build:
      context: ./apis
      dockerfile: Dockerfile
    container_name: market-data-collection-api
    ports:
      - "${DATA_API_PORT}:8000"
    environment:
      TZ: Europe/Rome
    depends_on:
      # Only depends on itself to start after infrastructure is ready
      kafka:
        condition: service_healthy
      postgres:
        condition: service_healthy
    networks:
      - common-network
    healthcheck:
      test: ["CMD", "curl", "-f", "${DATA_API_URL}/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 20s
    volumes:
      - ./apis:/app  # For development - live reload


  # Flink job manager and task manager for processing data
  flink-jobmanager:
    build: ./flink
    container_name: flink-jobmanager
    ports:
      - "8081:8081"  # Flink Web UI
    command: jobmanager
    # standalone-job --python /opt/flink/processing/src/jobs/price_analyzer.py
    depends_on:
      - kafka
      - postgres
      - market-data-producer
    environment:
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: flink-jobmanager

        jobmanager.memory.process.size: 1800m
        jobmanager.memory.jvm-overhead.min: 192m

        state.backend: filesystem
        state.checkpoints.dir: file:///tmp/flink-checkpoints
        heartbeat.interval: 1000
        heartbeat.timeout: 5000
        rest.flamegraph.enabled: true
        web.backpressure.refresh-interval: 10000
        execution.shutdown-on-application-finish: false
      - FLINK_LOCAL_TIME_ZONE=Europe/Rome
      - TZ=Europe/Rome
      - ALERTS_KAFKA_STARTUP_MODE=latest-offset
      - UNDERCUT_PERCENT_THRESHOLD=${UNDERCUT_PERCENT_THRESHOLD}
      - OVERPRICED_PERCENT_THRESHOLD=${OVERPRICED_PERCENT_THRESHOLD}
      - PRICE_INCREASE_24HRS_THRESHOLD=${PRICE_INCREASE_24HRS_THRESHOLD}
      - KAFKA_TOPIC=${COMPETITOR_PRICES}
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8081/overview"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 20s
    volumes:
      - ./flink:/opt/flink/app
      - flink_data:/tmp/
    networks:
      - common-network
  flink-taskmanager:
    build: ./flink
    container_name: flink-taskmanager
    command: taskmanager
    depends_on:
      - flink-jobmanager
      - kafka
      - postgres
      - market-data-producer
    environment:
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: flink-jobmanager
        taskmanager.memory.process.size: 3072m
        taskmanager.numberOfTaskSlots: 8
        state.backend: filesystem
        state.checkpoints.dir: file:///tmp/flink-checkpoints
        heartbeat.interval: 1000
        heartbeat.timeout: 5000
      - FLINK_LOCAL_TIME_ZONE=Europe/Rome
      - TZ=Europe/Rome
    volumes:
      - flink_data:/tmp/
    networks:
      - common-network

  # Market data Kafka producer
  market-data-producer:
    build:
      context: ./kafka
      dockerfile: Dockerfile
    container_name: market-data-producer
    depends_on:
      kafka:
        condition: service_healthy
      market-data-api:
        condition: service_healthy
    environment:
      - KAFKA_BOOTSTRAP_SERVER=${KAFKA_BOOTSTRAP_SERVER}
      - DATA_API_INTERNAL_URL=${DATA_API_INTERNAL_URL}
      - COLLECTION_INTERVAL=${COLLECTION_INTERVAL}
    command: ["python", "producers/market_data_producer.py"]
    volumes:
      - ./kafka:/kafka  # live-reload code for development
    networks:
      - common-network

  # User behavior producer
  user-behavior-producer:
    build:
      context: ./kafka
      dockerfile: Dockerfile
    container_name: user-behavior-producer
    depends_on:
      kafka:
        condition: service_healthy
      market-data-api:
        condition: service_healthy
    environment:
      - KAFKA_BOOTSTRAP_SERVER=${KAFKA_BOOTSTRAP_SERVER}
      - DATA_API_INTERNAL_URL=${DATA_API_INTERNAL_URL}
      - USER_BEHAVIOR_INTERVAL=${USER_BEHAVIOR_INTERVAL}
    command: ["python", "producers/user_behavior_producer.py"]
    volumes:
      - ./kafka:/kafka
    networks:
      - common-network
  # Dashboard for price intelligence visualization
  dashboard:
    build:
      context: ./dashboard
      dockerfile: Dockerfile
    container_name: price-intelligence-dashboard
    ports:
      - "8501:8501"
    environment:
      - POSTGRES_URL=${POSTGRES_URL}
      - ALERT_PERCENT_THRESHOLD=${ALERT_PERCENT_THRESHOLD}
      - UNDERCUT_PERCENT_THRESHOLD=${UNDERCUT_PERCENT_THRESHOLD}
      - OVERPRICED_PERCENT_THRESHOLD=${OVERPRICED_PERCENT_THRESHOLD}
      - PRICE_INCREASE_24HRS_THRESHOLD=${PRICE_INCREASE_24HRS_THRESHOLD}
    depends_on:
      - postgres
    volumes:
      - ./dashboard:/app
    networks:
      - common-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8501"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s

  # Price sensitivity updater (ml-based elasticity)
  price-sensitivity-updater:
    build:
      context: ./ml_services/price_elasticity
      dockerfile: Dockerfile
    container_name: price-sensitivity-updater
    environment:
      - POSTGRES_DB=${POSTGRES_DB}
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_HOST=${POSTGRES_HOST}
      - POSTGRES_PORT=${POSTGRES_PORT}
      - PRICE_SENSITIVITY_REFRESH_SEC=60
      - DATA_API_INTERNAL_URL=${DATA_API_INTERNAL_URL}
      - MIN_ELASTICITY_OBSERVATIONS=${MIN_ELASTICITY_OBSERVATIONS}
    depends_on:
      kafka:
        condition: service_healthy
      market-data-api:
        condition: service_healthy
      postgres:
        condition: service_healthy
      flink-jobmanager:
        condition: service_healthy
    command: ["python", "price_sensitivity_updater.py"]
    volumes:
      - ./services/price_elasticity:/price_elasticity
    networks:
      - common-network

volumes:
  kafka-data:
  postgres_data:
  flink_data:
networks:
  common-network: